{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54969946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "from bs4 import BeautifulSoup # documentation available at : www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "import requests # sends http requests and access the page : docs.python-requests.org/en/latest/\n",
    "import csv # creates the output csv file\n",
    "#import unicodedata # works with string encoding of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c9cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "entry = []\n",
    "urlnumber = 2 # Give the page number to start with\n",
    "\n",
    "while len(entries) <= 5100: # Give the entry count to end with\n",
    "\n",
    "    url = 'http://forums.edmunds.com/discussion/2864/general/x/entry-level-luxury-performance-sedans/p%d' % (urlnumber,) # Give the url of the forum, excluding the page number in the hyperlink\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, timeout = 10) # Sending a request to access the page\n",
    "    except Exception as e:\n",
    "        print(\"Error message:\",e)\n",
    "        break;\n",
    "\n",
    "    data = r.text\n",
    "    \n",
    "    soup = BeautifulSoup(data, 'lxml') # Getting the page source into the soup\n",
    "    \n",
    "    for div in soup.find_all('div'):\n",
    "        entry = []\n",
    "        if(div.get('class') != None and div.get('class')[0] == 'Comment'): # A single post is referred to as a comment. Each comment is a block denoted in a div tag which has a class called comment.\n",
    "            ps = div.find_all('p') # gets all the tags called p to a variable ps\n",
    "            aas = div.find_all('a') # gets all the tags called a to a variable aas\n",
    "            spans = div.find_all('span')\n",
    "            times = div.find_all('time') # used to extract the time tag which gives the iDate of the post\n",
    "\n",
    "            concat_str = ''\n",
    "            for str in aas[1].contents: # prints the contents that is between the tag start and end\n",
    "                if str != \"<br>\" or str != \"<br/>\": # breaks in post which we need to work around\n",
    "                    concat_str = (concat_str + ' '+ str).encode(\"utf-8\").strip() # the format extracted is a unicode - we need a uniform structure to work with the strings\n",
    "            entry.append(concat_str)\n",
    "\n",
    "            concat_str = ''\n",
    "            for str in times[0].contents:\n",
    "                if str != \"<br>\" or str != \"<br/>\":\n",
    "                    concat_str = (concat_str + ' '+ str).encode('iso-8859-1').strip()\n",
    "            entry.append(concat_str)\n",
    "\n",
    "            for div in div.find_all('div'):\n",
    "                if (div.get('class') != None and div.get('class')[0] == 'Message'): # extracting the div tag with the class attribute as message\n",
    "                    blockquotes = []\n",
    "                    x = div.get_text()\n",
    "                    for bl in div.find_all('blockquote'):\n",
    "                        blockquotes.append(bl.get_text()) # block quote is used to get the quote made by a person. get_text helps to eliminate the hyperlinks and pulls out only the data.\n",
    "                        bl.decompose()\n",
    "                    # Encoding the text to ascii code by replacing the non-ascii characters\n",
    "                    ascii_encoding = div.get_text().replace(\"\\n\",\" \").replace(\"<br/>\",\"\").encode('ascii','replace')\n",
    "                    # Convert the ASCII encoding to Latin1 encoding\n",
    "                    latin1_encoding = ascii_encoding.decode('ascii').encode('iso-8859-1')\n",
    "                    # Append the encoding bytes to output list\n",
    "                    entry.append(latin1_encoding)\n",
    "\n",
    "                    for bl in blockquotes:\n",
    "                        ascii_encoding = bl.replace(\"\\n\",\" \").replace(\"<br/>\",\"\").encode('ascii','replace')\n",
    "                        latin1_encoding = ascii_encoding.decode('ascii').encode('iso-8859-1')\n",
    "                        entry.append(latin1_encoding)\n",
    "\n",
    "            entries.append(entry)\n",
    "            \n",
    "    urlnumber += 1\n",
    "\n",
    "# Convert a list of byte to list a of string     \n",
    "stringlist=[[x.decode('iso-8859-1') for x in entry] for entry in entries]\n",
    "# Save the list to a csv file\n",
    "with open('edmunds_extraction.csv', 'w') as output:\n",
    "    writer = csv.writer(output, quoting=csv.QUOTE_ALL)\n",
    "    writer.writerows(stringlist)\n",
    "\n",
    "print (\"Wrote to edmunds_extraction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f39e6",
   "metadata": {},
   "source": [
    "### Task A: Identify top 10 brands by frequency. From the posts, calculate lift ratios for associations between the brands. You will have to write a script to do this task. Show the brands on a multidimensional scaling (MDS) map. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e5a108",
   "metadata": {},
   "source": [
    "### Read in scrapped comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f354df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import MDS\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb2a44c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spacy.cli?\n",
    "# spacy.cli.download(\"en_core_web_sm\")\n",
    "from spacy.lang.en import stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe96d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir(r'/Users/yanhuanhuang/Desktop/MMA/INSY669-Text Analytics/Group Project/INSY669-Text-Analytics-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7eb6ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wishnhigh1</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>The problem is that they are HUGE generalizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kd6aw1</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>Have found out that with some of the more pow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fwatson</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>How does your theory explain English cars? A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dave330i</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>\"Being that it is an automatic I can enjoy my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blueguydotcom</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>He did mention \"in rush hour traffic.\" Like t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>laurasdada</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>I had a '99 300M, loved it. New 300? Well, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5146</th>\n",
       "      <td>ivorypearlg</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>I've been in the 300M and 300C... Much differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>shipo</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>I don't know, maybe it's just me or maybe my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <td>dhanley</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>Actually, the m35x gets 17/24 mpg, same as th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <td>ivorypearlg</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>So sorry for the comparo... I should have did...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0           1  \\\n",
       "0        wishnhigh1  April 2002   \n",
       "1            kd6aw1  April 2002   \n",
       "2           fwatson  April 2002   \n",
       "3          dave330i  April 2002   \n",
       "4     blueguydotcom  April 2002   \n",
       "...             ...         ...   \n",
       "5145     laurasdada    May 2006   \n",
       "5146    ivorypearlg    May 2006   \n",
       "5147          shipo    May 2006   \n",
       "5148        dhanley    May 2006   \n",
       "5149    ivorypearlg    May 2006   \n",
       "\n",
       "                                                      2  \n",
       "0      The problem is that they are HUGE generalizat...  \n",
       "1      Have found out that with some of the more pow...  \n",
       "2      How does your theory explain English cars? A ...  \n",
       "3      \"Being that it is an automatic I can enjoy my...  \n",
       "4      He did mention \"in rush hour traffic.\" Like t...  \n",
       "...                                                 ...  \n",
       "5145   I had a '99 300M, loved it. New 300? Well, th...  \n",
       "5146   I've been in the 300M and 300C... Much differ...  \n",
       "5147   I don't know, maybe it's just me or maybe my ...  \n",
       "5148   Actually, the m35x gets 17/24 mpg, same as th...  \n",
       "5149   So sorry for the comparo... I should have did...  \n",
       "\n",
       "[5150 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Documents\n",
    "doc = pd.read_csv('edmunds_extraction.csv', header=None)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b47f0d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users</th>\n",
       "      <th>time</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wishnhigh1</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>The problem is that they are HUGE generalizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kd6aw1</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>Have found out that with some of the more pow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fwatson</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>How does your theory explain English cars? A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dave330i</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>\"Being that it is an automatic I can enjoy my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blueguydotcom</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>He did mention \"in rush hour traffic.\" Like t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           users        time  \\\n",
       "0     wishnhigh1  April 2002   \n",
       "1         kd6aw1  April 2002   \n",
       "2        fwatson  April 2002   \n",
       "3       dave330i  April 2002   \n",
       "4  blueguydotcom  April 2002   \n",
       "\n",
       "                                                 txt  \n",
       "0   The problem is that they are HUGE generalizat...  \n",
       "1   Have found out that with some of the more pow...  \n",
       "2   How does your theory explain English cars? A ...  \n",
       "3   \"Being that it is an automatic I can enjoy my...  \n",
       "4   He did mention \"in rush hour traffic.\" Like t...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add column name\n",
    "doc.columns = [\"users\", \"time\", \"txt\"]\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c022dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and lower case\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "tokens = []\n",
    "for i in range(len(doc)):\n",
    "    tokens.append(word_tokenize(doc.loc[i,'txt'].lower()))\n",
    "doc['txt_tokenized'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05a764da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users</th>\n",
       "      <th>time</th>\n",
       "      <th>txt</th>\n",
       "      <th>txt_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wishnhigh1</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>The problem is that they are HUGE generalizat...</td>\n",
       "      <td>[the, problem, is, that, they, are, huge, gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kd6aw1</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>Have found out that with some of the more pow...</td>\n",
       "      <td>[have, found, out, that, with, some, of, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fwatson</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>How does your theory explain English cars? A ...</td>\n",
       "      <td>[how, does, your, theory, explain, english, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dave330i</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>\"Being that it is an automatic I can enjoy my...</td>\n",
       "      <td>[``, being, that, it, is, an, automatic, i, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blueguydotcom</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>He did mention \"in rush hour traffic.\" Like t...</td>\n",
       "      <td>[he, did, mention, ``, in, rush, hour, traffic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>laurasdada</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>I had a '99 300M, loved it. New 300? Well, th...</td>\n",
       "      <td>[i, had, a, '99, 300m, ,, loved, it, ., new, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5146</th>\n",
       "      <td>ivorypearlg</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>I've been in the 300M and 300C... Much differ...</td>\n",
       "      <td>[i, 've, been, in, the, 300m, and, 300c, ..., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>shipo</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>I don't know, maybe it's just me or maybe my ...</td>\n",
       "      <td>[i, do, n't, know, ,, maybe, it, 's, just, me,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <td>dhanley</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>Actually, the m35x gets 17/24 mpg, same as th...</td>\n",
       "      <td>[actually, ,, the, m35x, gets, 17/24, mpg, ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <td>ivorypearlg</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>So sorry for the comparo... I should have did...</td>\n",
       "      <td>[so, sorry, for, the, comparo, ..., i, should,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              users        time  \\\n",
       "0        wishnhigh1  April 2002   \n",
       "1            kd6aw1  April 2002   \n",
       "2           fwatson  April 2002   \n",
       "3          dave330i  April 2002   \n",
       "4     blueguydotcom  April 2002   \n",
       "...             ...         ...   \n",
       "5145     laurasdada    May 2006   \n",
       "5146    ivorypearlg    May 2006   \n",
       "5147          shipo    May 2006   \n",
       "5148        dhanley    May 2006   \n",
       "5149    ivorypearlg    May 2006   \n",
       "\n",
       "                                                    txt  \\\n",
       "0      The problem is that they are HUGE generalizat...   \n",
       "1      Have found out that with some of the more pow...   \n",
       "2      How does your theory explain English cars? A ...   \n",
       "3      \"Being that it is an automatic I can enjoy my...   \n",
       "4      He did mention \"in rush hour traffic.\" Like t...   \n",
       "...                                                 ...   \n",
       "5145   I had a '99 300M, loved it. New 300? Well, th...   \n",
       "5146   I've been in the 300M and 300C... Much differ...   \n",
       "5147   I don't know, maybe it's just me or maybe my ...   \n",
       "5148   Actually, the m35x gets 17/24 mpg, same as th...   \n",
       "5149   So sorry for the comparo... I should have did...   \n",
       "\n",
       "                                          txt_tokenized  \n",
       "0     [the, problem, is, that, they, are, huge, gene...  \n",
       "1     [have, found, out, that, with, some, of, the, ...  \n",
       "2     [how, does, your, theory, explain, english, ca...  \n",
       "3     [``, being, that, it, is, an, automatic, i, ca...  \n",
       "4     [he, did, mention, ``, in, rush, hour, traffic...  \n",
       "...                                                 ...  \n",
       "5145  [i, had, a, '99, 300m, ,, loved, it, ., new, 3...  \n",
       "5146  [i, 've, been, in, the, 300m, and, 300c, ..., ...  \n",
       "5147  [i, do, n't, know, ,, maybe, it, 's, just, me,...  \n",
       "5148  [actually, ,, the, m35x, gets, 17/24, mpg, ,, ...  \n",
       "5149  [so, sorry, for, the, comparo, ..., i, should,...  \n",
       "\n",
       "[5150 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51155d43",
   "metadata": {},
   "source": [
    "### Read in models to brands mapping csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b76848e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acura</td>\n",
       "      <td>integra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acura</td>\n",
       "      <td>Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acura</td>\n",
       "      <td>vigor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acura</td>\n",
       "      <td>rlx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acura</td>\n",
       "      <td>ILX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>volvo</td>\n",
       "      <td>xc90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>volvo</td>\n",
       "      <td>s60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>volvo</td>\n",
       "      <td>s80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>volvo</td>\n",
       "      <td>v60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>volvo</td>\n",
       "      <td>c70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>528 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     brand    model\n",
       "0    acura  integra\n",
       "1    acura   Legend\n",
       "2    acura    vigor\n",
       "3    acura      rlx\n",
       "4    acura      ILX\n",
       "..     ...      ...\n",
       "523  volvo     xc90\n",
       "524  volvo      s60\n",
       "525  volvo      s80\n",
       "526  volvo      v60\n",
       "527  volvo      c70\n",
       "\n",
       "[528 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in brand model mapping csv\n",
    "model_brand_mapping = pd.read_csv(\"models (2).csv\", header = None)\n",
    "model_brand_mapping.columns = [\"brand\", \"model\"]\n",
    "model_brand_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "430283af",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_mapping = [{'brand': 'acura', 'model': 'tl'},\n",
    " {'brand': 'acura', 'model': 'tlx'},\n",
    " {'brand': 'acura', 'model': 'tlxs'},\n",
    " {'brand': 'alfaromeo', 'model': 'alfa'},\n",
    " {'brand': 'alfaromeo', 'model': 'giulia'},\n",
    " {'brand': 'audi', 'model': 'b8'},\n",
    " {'brand': 'audi', 'model': 'rs3'},\n",
    " {'brand': 'audi', 'model': 'rs4'},\n",
    " {'brand': 'audi', 'model': 'rs7'},\n",
    " {'brand': 'audi', 'model': 'rsq3'},\n",
    " {'brand': 'audi', 'model': 'rsq5'},\n",
    " {'brand': 'audi', 'model': 's3'},\n",
    " {'brand': 'audi', 'model': 's4'},\n",
    " {'brand': 'audi', 'model': 's5'},\n",
    " {'brand': 'audi', 'model': 's6'},\n",
    " {'brand': 'audi', 'model': 's8'},\n",
    " {'brand': 'audi', 'model': 'sq3'},\n",
    " {'brand': 'audi', 'model': 'sq5'},\n",
    " {'brand': 'audi', 'model': 'tt'},\n",
    " {'brand': 'bmw', 'model': '135i'},\n",
    " {'brand': 'bmw', 'model': '3 series'},\n",
    " {'brand': 'bmw', 'model': '320'},\n",
    " {'brand': 'bmw', 'model': '320i'},\n",
    " {'brand': 'bmw', 'model': '320xi'},\n",
    " {'brand': 'bmw', 'model': '325i'},\n",
    " {'brand': 'bmw', 'model': '328'},\n",
    " {'brand': 'bmw', 'model': '328 wagon'},\n",
    " {'brand': 'bmw', 'model': '328d'},\n",
    " {'brand': 'bmw', 'model': '328xd'},\n",
    " {'brand': 'bmw', 'model': '328xi'},\n",
    " {'brand': 'bmw', 'model': '330'},\n",
    " {'brand': 'bmw', 'model': '330i'},\n",
    " {'brand': 'bmw', 'model': '335'},\n",
    " {'brand': 'bmw', 'model': '335is'},\n",
    " {'brand': 'bmw', 'model': '335xi'},\n",
    " {'brand': 'bmw', 'model': '340i'},\n",
    " {'brand': 'bmw', 'model': '430'},\n",
    " {'brand': 'bmw', 'model': '435i'},\n",
    " {'brand': 'bmw', 'model': '440'},\n",
    " {'brand': 'bmw', 'model': '440i'},\n",
    " {'brand': 'bmw', 'model': '530i'},\n",
    " {'brand': 'bmw', 'model': '535d'},\n",
    " {'brand': 'bmw', 'model': '550i'},\n",
    " {'brand': 'bmw', 'model': 'e36'},\n",
    " {'brand': 'bmw', 'model': 'e39'},\n",
    " {'brand': 'bmw', 'model': 'e46'},\n",
    " {'brand': 'bmw', 'model': 'e83'},\n",
    " {'brand': 'bmw', 'model': 'e90'},\n",
    " {'brand': 'bmw', 'model': 'e90s'},\n",
    " {'brand': 'bmw', 'model': 'e91'},\n",
    " {'brand': 'bmw', 'model': 'e92'},\n",
    " {'brand': 'bmw', 'model': 'f10'},\n",
    " {'brand': 'bmw', 'model': 'f30'},\n",
    " {'brand': 'bmw', 'model': 'm2'},\n",
    " {'brand': 'bmw', 'model': 'm235'},\n",
    " {'brand': 'bmw', 'model': 'm235i'},\n",
    " {'brand': 'bmw', 'model': 'm2c'},\n",
    " {'brand': 'bmw', 'model': 'm325i'},\n",
    " {'brand': 'bmw', 'model': 'm4'},\n",
    " {'brand': 'bmw', 'model': 'm50'},\n",
    " {'brand': 'bmw', 'model': 'x1'},\n",
    " {'brand': 'bmw', 'model': 'x3'},\n",
    " {'brand': 'bmw', 'model': 'x5'},\n",
    " {'brand': 'bmw', 'model': 'x6'},\n",
    " {'brand': 'bmw', 'model': 'zhp'},\n",
    " {'brand': 'cadillac', 'model': 'ats'},\n",
    " {'brand': 'cadillac', 'model': 'caddy'},\n",
    " {'brand': 'cadillac', 'model': \"cadillac's\"},\n",
    " {'brand': 'cadillac', 'model': 'xt5'},\n",
    " {'brand': 'chevrolet', 'model': 'vette'},\n",
    " {'brand': 'chrysler', 'model': '300c'},           \n",
    " {'brand': 'ford', 'model': 'gt350'},\n",
    " {'brand': 'ford', 'model': 'gt'},\n",
    " {'brand': 'hyundai', 'model': 'g70'},\n",
    " {'brand': 'hyundai', 'model': 'g80'},\n",
    " {'brand': 'infiniti', 'model': 'g35'},\n",
    " {'brand': 'infiniti', 'model': 'g37s'},\n",
    " {'brand': 'infiniti', 'model': 'g37x'},\n",
    " {'brand': 'infiniti', 'model': 'infinity'},\n",
    " {'brand': 'infiniti', 'model': 'jx'},\n",
    " {'brand': 'infiniti', 'model': 'm35x'},\n",
    " {'brand': 'infiniti', 'model': 'm37'},\n",
    " {'brand': 'infiniti', 'model': 'q40'},\n",
    " {'brand': 'infiniti', 'model': 'q50s'},\n",
    " {'brand': 'infiniti', 'model': 'qx56'},\n",
    " {'brand': 'jaguar', 'model': 'jag'},\n",
    " {'brand': 'jaguar', 'model': 'rover'},\n",
    " {'brand': 'jaguar', 'model': 'xf'},\n",
    " {'brand': 'kia', 'model': 'stinger'},\n",
    " {'brand': 'lexus', 'model': 'ct200h'},\n",
    " {'brand': 'lexus', 'model': 'es350'},\n",
    " {'brand': 'lexus', 'model': 'f-sport'},\n",
    " {'brand': 'lexus', 'model': 'gs350'},\n",
    " {'brand': 'lexus', 'model': 'lexi'},\n",
    " {'brand': 'lexus', 'model': 'nx'},\n",
    " {'brand': 'lexus', 'model': 'rx350'},\n",
    " {'brand': 'mazda', 'model': 'ms3'},\n",
    " {'brand': 'mercedes', 'model': 'amg'},\n",
    " {'brand': 'mercedes', 'model': 'c250'},\n",
    " {'brand': 'mercedes', 'model': 'c250s'},\n",
    " {'brand': 'mercedes', 'model': \"c250's\"},\n",
    " {'brand': 'mercedes', 'model': 'c300'},\n",
    " {'brand': 'mercedes', 'model': 'c350'},\n",
    " {'brand': 'mercedes', 'model': 'c400'},\n",
    " {'brand': 'mercedes', 'model': 'c63'},\n",
    " {'brand': 'mercedes', 'model': 'cla'},\n",
    " {'brand': 'mercedes', 'model': 'mb'},\n",
    " {'brand': 'mitsubishi', 'model': 'mitsubishi'},                \n",
    " {'brand': 'nissan', 'model': 'quest'},\n",
    " {'brand': 'nissan', 'model': 'ultima'},\n",
    " {'brand': 'porsche', 'model': 'porsche'},\n",
    " {'brand': 'saab', 'model': 'saab'},\n",
    " {'brand': 'saab', 'model': 'saabs'},\n",
    "#  {'brand': 'skoda', 'model': 'skoda'},\n",
    " {'brand': 'subaru', 'model': 'b9'},\n",
    "#  {'brand': 'tesla', 'model': 'tesla'},\n",
    " {'brand': 'volvo', 'model': 's60r'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38d0104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_mapping = pd.DataFrame(extra_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e46582f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acura</td>\n",
       "      <td>integra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acura</td>\n",
       "      <td>Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acura</td>\n",
       "      <td>vigor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acura</td>\n",
       "      <td>rlx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acura</td>\n",
       "      <td>ILX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>porsche</td>\n",
       "      <td>porsche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>saab</td>\n",
       "      <td>saab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>saab</td>\n",
       "      <td>saabs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>subaru</td>\n",
       "      <td>b9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>volvo</td>\n",
       "      <td>s60r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>643 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       brand    model\n",
       "0      acura  integra\n",
       "1      acura   Legend\n",
       "2      acura    vigor\n",
       "3      acura      rlx\n",
       "4      acura      ILX\n",
       "..       ...      ...\n",
       "638  porsche  porsche\n",
       "639     saab     saab\n",
       "640     saab    saabs\n",
       "641   subaru       b9\n",
       "642    volvo     s60r\n",
       "\n",
       "[643 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_mapping = pd.concat([model_brand_mapping, extra_mapping], ignore_index=True)\n",
    "combined_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8557aea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicates\n",
    "combined_mapping[combined_mapping.duplicated()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d234a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn df into dictionary\n",
    "models = combined_mapping[\"model\"].tolist()\n",
    "brands = combined_mapping[\"brand\"].tolist()\n",
    "mapping_dict = {}\n",
    "\n",
    "for i in range(len(models)):\n",
    "    mapping_dict[models[i].lower()] = brands[i]\n",
    "\n",
    "# mapping_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20373c5",
   "metadata": {},
   "source": [
    "### Replace model in txt to brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b344b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_brand(lst):\n",
    "    \n",
    "    new_lst = []\n",
    "    for word in lst:\n",
    "        new_lst.append(mapping_dict.get(word, word))\n",
    "        \n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "946ff2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users</th>\n",
       "      <th>time</th>\n",
       "      <th>txt</th>\n",
       "      <th>txt_tokenized</th>\n",
       "      <th>txt_token_mapped</th>\n",
       "      <th>txt_wo_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wishnhigh1</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>The problem is that they are HUGE generalizat...</td>\n",
       "      <td>[the, problem, is, that, they, are, huge, gene...</td>\n",
       "      <td>[the, problem, is, that, they, are, huge, gene...</td>\n",
       "      <td>[problem, huge, generalizations, talking, japa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kd6aw1</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>Have found out that with some of the more pow...</td>\n",
       "      <td>[have, found, out, that, with, some, of, the, ...</td>\n",
       "      <td>[have, found, out, that, with, some, of, the, ...</td>\n",
       "      <td>[found, powerful, car, like, infiniti, chevrol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fwatson</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>How does your theory explain English cars? A ...</td>\n",
       "      <td>[how, does, your, theory, explain, english, ca...</td>\n",
       "      <td>[how, does, your, theory, explain, english, ca...</td>\n",
       "      <td>[theory, explain, english, car, country, steep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dave330i</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>\"Being that it is an automatic I can enjoy my...</td>\n",
       "      <td>[``, being, that, it, is, an, automatic, i, ca...</td>\n",
       "      <td>[``, being, that, it, is, an, automatic, i, ca...</td>\n",
       "      <td>[automatic, enjoy, coffee, shave, talk, cel, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blueguydotcom</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>He did mention \"in rush hour traffic.\" Like t...</td>\n",
       "      <td>[he, did, mention, ``, in, rush, hour, traffic...</td>\n",
       "      <td>[he, did, mention, ``, in, rush, hour, traffic...</td>\n",
       "      <td>[mention, rush, hour, traffic, like, bumper-to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>laurasdada</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>I had a '99 300M, loved it. New 300? Well, th...</td>\n",
       "      <td>[i, had, a, '99, 300m, ,, loved, it, ., new, 3...</td>\n",
       "      <td>[i, had, a, '99, chrysler, ,, loved, it, ., ne...</td>\n",
       "      <td>['99, chrysler, loved, new, 300, styling, sent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5146</th>\n",
       "      <td>ivorypearlg</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>I've been in the 300M and 300C... Much differ...</td>\n",
       "      <td>[i, 've, been, in, the, 300m, and, 300c, ..., ...</td>\n",
       "      <td>[i, 've, been, in, the, chrysler, and, chrysle...</td>\n",
       "      <td>[chrysler, chrysler, different, car, m, drove,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>shipo</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>I don't know, maybe it's just me or maybe my ...</td>\n",
       "      <td>[i, do, n't, know, ,, maybe, it, 's, just, me,...</td>\n",
       "      <td>[i, do, n't, know, ,, maybe, it, 's, just, me,...</td>\n",
       "      <td>[know, maybe, maybe, detroit, roots, showing, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <td>dhanley</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>Actually, the m35x gets 17/24 mpg, same as th...</td>\n",
       "      <td>[actually, ,, the, m35x, gets, 17/24, mpg, ,, ...</td>\n",
       "      <td>[actually, ,, the, infiniti, gets, 17/24, mpg,...</td>\n",
       "      <td>[actually, infiniti, gets, 17/24, mpg, chrysle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <td>ivorypearlg</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>So sorry for the comparo... I should have did...</td>\n",
       "      <td>[so, sorry, for, the, comparo, ..., i, should,...</td>\n",
       "      <td>[so, sorry, for, the, comparo, ..., i, should,...</td>\n",
       "      <td>[sorry, comparo, research, gas, mileage, compa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              users        time  \\\n",
       "0        wishnhigh1  April 2002   \n",
       "1            kd6aw1  April 2002   \n",
       "2           fwatson  April 2002   \n",
       "3          dave330i  April 2002   \n",
       "4     blueguydotcom  April 2002   \n",
       "...             ...         ...   \n",
       "5145     laurasdada    May 2006   \n",
       "5146    ivorypearlg    May 2006   \n",
       "5147          shipo    May 2006   \n",
       "5148        dhanley    May 2006   \n",
       "5149    ivorypearlg    May 2006   \n",
       "\n",
       "                                                    txt  \\\n",
       "0      The problem is that they are HUGE generalizat...   \n",
       "1      Have found out that with some of the more pow...   \n",
       "2      How does your theory explain English cars? A ...   \n",
       "3      \"Being that it is an automatic I can enjoy my...   \n",
       "4      He did mention \"in rush hour traffic.\" Like t...   \n",
       "...                                                 ...   \n",
       "5145   I had a '99 300M, loved it. New 300? Well, th...   \n",
       "5146   I've been in the 300M and 300C... Much differ...   \n",
       "5147   I don't know, maybe it's just me or maybe my ...   \n",
       "5148   Actually, the m35x gets 17/24 mpg, same as th...   \n",
       "5149   So sorry for the comparo... I should have did...   \n",
       "\n",
       "                                          txt_tokenized  \\\n",
       "0     [the, problem, is, that, they, are, huge, gene...   \n",
       "1     [have, found, out, that, with, some, of, the, ...   \n",
       "2     [how, does, your, theory, explain, english, ca...   \n",
       "3     [``, being, that, it, is, an, automatic, i, ca...   \n",
       "4     [he, did, mention, ``, in, rush, hour, traffic...   \n",
       "...                                                 ...   \n",
       "5145  [i, had, a, '99, 300m, ,, loved, it, ., new, 3...   \n",
       "5146  [i, 've, been, in, the, 300m, and, 300c, ..., ...   \n",
       "5147  [i, do, n't, know, ,, maybe, it, 's, just, me,...   \n",
       "5148  [actually, ,, the, m35x, gets, 17/24, mpg, ,, ...   \n",
       "5149  [so, sorry, for, the, comparo, ..., i, should,...   \n",
       "\n",
       "                                       txt_token_mapped  \\\n",
       "0     [the, problem, is, that, they, are, huge, gene...   \n",
       "1     [have, found, out, that, with, some, of, the, ...   \n",
       "2     [how, does, your, theory, explain, english, ca...   \n",
       "3     [``, being, that, it, is, an, automatic, i, ca...   \n",
       "4     [he, did, mention, ``, in, rush, hour, traffic...   \n",
       "...                                                 ...   \n",
       "5145  [i, had, a, '99, chrysler, ,, loved, it, ., ne...   \n",
       "5146  [i, 've, been, in, the, chrysler, and, chrysle...   \n",
       "5147  [i, do, n't, know, ,, maybe, it, 's, just, me,...   \n",
       "5148  [actually, ,, the, infiniti, gets, 17/24, mpg,...   \n",
       "5149  [so, sorry, for, the, comparo, ..., i, should,...   \n",
       "\n",
       "                                       txt_wo_stopwords  \n",
       "0     [problem, huge, generalizations, talking, japa...  \n",
       "1     [found, powerful, car, like, infiniti, chevrol...  \n",
       "2     [theory, explain, english, car, country, steep...  \n",
       "3     [automatic, enjoy, coffee, shave, talk, cel, p...  \n",
       "4     [mention, rush, hour, traffic, like, bumper-to...  \n",
       "...                                                 ...  \n",
       "5145  ['99, chrysler, loved, new, 300, styling, sent...  \n",
       "5146  [chrysler, chrysler, different, car, m, drove,...  \n",
       "5147  [know, maybe, maybe, detroit, roots, showing, ...  \n",
       "5148  [actually, infiniti, gets, 17/24, mpg, chrysle...  \n",
       "5149  [sorry, comparo, research, gas, mileage, compa...  \n",
       "\n",
       "[5150 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[\"txt_token_mapped\"] = doc[\"txt_tokenized\"].apply(model_to_brand)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f83ca3",
   "metadata": {},
   "source": [
    "### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8214b69",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'STOP_WORDS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stop_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(stop_words\u001b[38;5;241m.\u001b[39mSTOP_WORDS)\n\u001b[1;32m      2\u001b[0m punc \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m``\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m–\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m&\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'STOP_WORDS'"
     ]
    }
   ],
   "source": [
    "stop_words = list(stop_words.STOP_WORDS)\n",
    "punc = ['.',',','!','?',';',':',\"'\",\"''\", '\"','``','(',')','[',']','{','}','-','...','–', '/','\\\\','&','%','$','#','@','+',\n",
    "    '*','=','>','<','|','~','_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e61bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(lst):\n",
    "    \n",
    "    tokens_wo_stopwords = []\n",
    "    for word in lst:\n",
    "        if word not in stop_words:\n",
    "            if word not in punc:\n",
    "                tokens_wo_stopwords.append(word)\n",
    "    return tokens_wo_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6199eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc[\"txt_wo_stopwords\"] = doc[\"txt_token_mapped\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e499902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users</th>\n",
       "      <th>time</th>\n",
       "      <th>txt</th>\n",
       "      <th>txt_tokenized</th>\n",
       "      <th>txt_token_mapped</th>\n",
       "      <th>txt_wo_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wishnhigh1</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>The problem is that they are HUGE generalizat...</td>\n",
       "      <td>[the, problem, is, that, they, are, huge, gene...</td>\n",
       "      <td>[the, problem, is, that, they, are, huge, gene...</td>\n",
       "      <td>[problem, huge, generalizations, talking, japa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kd6aw1</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>Have found out that with some of the more pow...</td>\n",
       "      <td>[have, found, out, that, with, some, of, the, ...</td>\n",
       "      <td>[have, found, out, that, with, some, of, the, ...</td>\n",
       "      <td>[found, powerful, car, like, infiniti, chevrol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fwatson</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>How does your theory explain English cars? A ...</td>\n",
       "      <td>[how, does, your, theory, explain, english, ca...</td>\n",
       "      <td>[how, does, your, theory, explain, english, ca...</td>\n",
       "      <td>[theory, explain, english, car, country, steep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dave330i</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>\"Being that it is an automatic I can enjoy my...</td>\n",
       "      <td>[``, being, that, it, is, an, automatic, i, ca...</td>\n",
       "      <td>[``, being, that, it, is, an, automatic, i, ca...</td>\n",
       "      <td>[automatic, enjoy, coffee, shave, talk, cel, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blueguydotcom</td>\n",
       "      <td>April 2002</td>\n",
       "      <td>He did mention \"in rush hour traffic.\" Like t...</td>\n",
       "      <td>[he, did, mention, ``, in, rush, hour, traffic...</td>\n",
       "      <td>[he, did, mention, ``, in, rush, hour, traffic...</td>\n",
       "      <td>[mention, rush, hour, traffic, like, bumper-to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>laurasdada</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>I had a '99 300M, loved it. New 300? Well, th...</td>\n",
       "      <td>[i, had, a, '99, 300m, ,, loved, it, ., new, 3...</td>\n",
       "      <td>[i, had, a, '99, chrysler, ,, loved, it, ., ne...</td>\n",
       "      <td>['99, chrysler, loved, new, 300, styling, sent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5146</th>\n",
       "      <td>ivorypearlg</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>I've been in the 300M and 300C... Much differ...</td>\n",
       "      <td>[i, 've, been, in, the, 300m, and, 300c, ..., ...</td>\n",
       "      <td>[i, 've, been, in, the, chrysler, and, chrysle...</td>\n",
       "      <td>[chrysler, chrysler, different, car, m, drove,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>shipo</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>I don't know, maybe it's just me or maybe my ...</td>\n",
       "      <td>[i, do, n't, know, ,, maybe, it, 's, just, me,...</td>\n",
       "      <td>[i, do, n't, know, ,, maybe, it, 's, just, me,...</td>\n",
       "      <td>[know, maybe, maybe, detroit, roots, showing, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <td>dhanley</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>Actually, the m35x gets 17/24 mpg, same as th...</td>\n",
       "      <td>[actually, ,, the, m35x, gets, 17/24, mpg, ,, ...</td>\n",
       "      <td>[actually, ,, the, infiniti, gets, 17/24, mpg,...</td>\n",
       "      <td>[actually, infiniti, gets, 17/24, mpg, chrysle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <td>ivorypearlg</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>So sorry for the comparo... I should have did...</td>\n",
       "      <td>[so, sorry, for, the, comparo, ..., i, should,...</td>\n",
       "      <td>[so, sorry, for, the, comparo, ..., i, should,...</td>\n",
       "      <td>[sorry, comparo, research, gas, mileage, compa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              users        time  \\\n",
       "0        wishnhigh1  April 2002   \n",
       "1            kd6aw1  April 2002   \n",
       "2           fwatson  April 2002   \n",
       "3          dave330i  April 2002   \n",
       "4     blueguydotcom  April 2002   \n",
       "...             ...         ...   \n",
       "5145     laurasdada    May 2006   \n",
       "5146    ivorypearlg    May 2006   \n",
       "5147          shipo    May 2006   \n",
       "5148        dhanley    May 2006   \n",
       "5149    ivorypearlg    May 2006   \n",
       "\n",
       "                                                    txt  \\\n",
       "0      The problem is that they are HUGE generalizat...   \n",
       "1      Have found out that with some of the more pow...   \n",
       "2      How does your theory explain English cars? A ...   \n",
       "3      \"Being that it is an automatic I can enjoy my...   \n",
       "4      He did mention \"in rush hour traffic.\" Like t...   \n",
       "...                                                 ...   \n",
       "5145   I had a '99 300M, loved it. New 300? Well, th...   \n",
       "5146   I've been in the 300M and 300C... Much differ...   \n",
       "5147   I don't know, maybe it's just me or maybe my ...   \n",
       "5148   Actually, the m35x gets 17/24 mpg, same as th...   \n",
       "5149   So sorry for the comparo... I should have did...   \n",
       "\n",
       "                                          txt_tokenized  \\\n",
       "0     [the, problem, is, that, they, are, huge, gene...   \n",
       "1     [have, found, out, that, with, some, of, the, ...   \n",
       "2     [how, does, your, theory, explain, english, ca...   \n",
       "3     [``, being, that, it, is, an, automatic, i, ca...   \n",
       "4     [he, did, mention, ``, in, rush, hour, traffic...   \n",
       "...                                                 ...   \n",
       "5145  [i, had, a, '99, 300m, ,, loved, it, ., new, 3...   \n",
       "5146  [i, 've, been, in, the, 300m, and, 300c, ..., ...   \n",
       "5147  [i, do, n't, know, ,, maybe, it, 's, just, me,...   \n",
       "5148  [actually, ,, the, m35x, gets, 17/24, mpg, ,, ...   \n",
       "5149  [so, sorry, for, the, comparo, ..., i, should,...   \n",
       "\n",
       "                                       txt_token_mapped  \\\n",
       "0     [the, problem, is, that, they, are, huge, gene...   \n",
       "1     [have, found, out, that, with, some, of, the, ...   \n",
       "2     [how, does, your, theory, explain, english, ca...   \n",
       "3     [``, being, that, it, is, an, automatic, i, ca...   \n",
       "4     [he, did, mention, ``, in, rush, hour, traffic...   \n",
       "...                                                 ...   \n",
       "5145  [i, had, a, '99, chrysler, ,, loved, it, ., ne...   \n",
       "5146  [i, 've, been, in, the, chrysler, and, chrysle...   \n",
       "5147  [i, do, n't, know, ,, maybe, it, 's, just, me,...   \n",
       "5148  [actually, ,, the, infiniti, gets, 17/24, mpg,...   \n",
       "5149  [so, sorry, for, the, comparo, ..., i, should,...   \n",
       "\n",
       "                                       txt_wo_stopwords  \n",
       "0     [problem, huge, generalizations, talking, japa...  \n",
       "1     [found, powerful, car, like, infiniti, chevrol...  \n",
       "2     [theory, explain, english, car, country, steep...  \n",
       "3     [automatic, enjoy, coffee, shave, talk, cel, p...  \n",
       "4     [mention, rush, hour, traffic, like, bumper-to...  \n",
       "...                                                 ...  \n",
       "5145  ['99, chrysler, loved, new, 300, styling, sent...  \n",
       "5146  [chrysler, chrysler, different, car, m, drove,...  \n",
       "5147  [know, maybe, maybe, detroit, roots, showing, ...  \n",
       "5148  [actually, infiniti, gets, 17/24, mpg, chrysle...  \n",
       "5149  [sorry, comparo, research, gas, mileage, compa...  \n",
       "\n",
       "[5150 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2342fde0",
   "metadata": {},
   "source": [
    "### Brand frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "360f6b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_combined = []\n",
    "\n",
    "for i in range(len(doc)):\n",
    "    txt_combined.extend(doc.loc[i, \"txt_wo_stopwords\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00aadb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 372,\n",
       " 'huge': 69,\n",
       " 'generalizations': 4,\n",
       " 'talking': 203,\n",
       " 'japanese': 196,\n",
       " 'exclusivly': 1,\n",
       " 'honda': 654,\n",
       " 'toyota': 405,\n",
       " 'subaru': 370,\n",
       " 'mazda': 99,\n",
       " 'isuzu': 4,\n",
       " 'mitsubishi': 27,\n",
       " 'daihatsu': 2,\n",
       " 'suzuki': 21,\n",
       " 'far': 290,\n",
       " 'makes': 289,\n",
       " 'culture': 5,\n",
       " 'american': 139,\n",
       " 'european': 88,\n",
       " 'capable': 46,\n",
       " 'having': 193,\n",
       " 'higher': 134,\n",
       " 'quality': 205,\n",
       " '70': 58,\n",
       " 'car': 5916,\n",
       " 'help': 99,\n",
       " 'generalization': 5,\n",
       " 'stop': 108,\n",
       " 'brands': 89,\n",
       " 'nations': 1,\n",
       " 'found': 144,\n",
       " 'powerful': 93,\n",
       " 'like': 1835,\n",
       " 'infiniti': 1922,\n",
       " 'chevrolet': 184,\n",
       " 'difference': 315,\n",
       " 'performance': 914,\n",
       " 'practical': 25,\n",
       " 'standpoint': 12,\n",
       " 'issue': 145,\n",
       " 'faster': 180,\n",
       " 'dream': 17,\n",
       " 'driving': 774,\n",
       " 'killing': 4,\n",
       " 'getting': 324,\n",
       " 'tickets': 3,\n",
       " 'time': 603,\n",
       " 'automatic': 226,\n",
       " 'love': 268,\n",
       " 'enjoy': 126,\n",
       " 'coffee': 6,\n",
       " 'shave': 4,\n",
       " 'talk': 90,\n",
       " 'cel': 3,\n",
       " 'phone': 34,\n",
       " 'hug': 5,\n",
       " 'wife': 146,\n",
       " 'rush': 18,\n",
       " 'hour': 28,\n",
       " 'traffic': 115,\n",
       " 'feel': 419,\n",
       " 'urge': 2,\n",
       " 'shift': 92,\n",
       " 'manumatic': 12,\n",
       " 'pretend': 5,\n",
       " 'stick': 95,\n",
       " 'ferrari': 44,\n",
       " 'paddle': 22,\n",
       " 'shifting': 35,\n",
       " 'want': 738,\n",
       " 'clutch': 93,\n",
       " 'opinion': 223,\n",
       " 'paulel': 1,\n",
       " 'cajon': 1,\n",
       " 'california': 22,\n",
       " 'theory': 23,\n",
       " 'explain': 20,\n",
       " 'english': 8,\n",
       " 'country': 45,\n",
       " 'steeped': 2,\n",
       " 'tradition': 4,\n",
       " 'producing': 12,\n",
       " 'poor': 68,\n",
       " 'little': 381,\n",
       " 'inovation': 1,\n",
       " 'look': 474,\n",
       " 'traditionalist': 1,\n",
       " 'managed': 23,\n",
       " 'acura': 2697,\n",
       " 'produced': 20,\n",
       " 'stirling': 1,\n",
       " 'lol====================================': 1,\n",
       " 'quote': 46,\n",
       " 'wishnhigh1': 1,\n",
       " '====================================': 1,\n",
       " 'general': 68,\n",
       " 'reflect': 17,\n",
       " 'perfectionist': 1,\n",
       " 'attitude': 22,\n",
       " '1pierce': 1,\n",
       " 'post': 200,\n",
       " 'virtually': 18,\n",
       " 'exception': 14,\n",
       " 'overall': 149,\n",
       " 'brand': 250,\n",
       " 'especially': 157,\n",
       " 'fit': 84,\n",
       " 'finish': 28,\n",
       " 'considerably': 9,\n",
       " 'excels': 5,\n",
       " 'read': 225,\n",
       " 'management': 6,\n",
       " 'accepting': 1,\n",
       " 'mediocre': 11,\n",
       " 'craftsmanship': 1,\n",
       " 'abilities': 7,\n",
       " 'assembly': 9,\n",
       " 'line': 207,\n",
       " 'workers': 1,\n",
       " 'point': 411,\n",
       " 'high': 247,\n",
       " 'level': 200,\n",
       " 'innovation': 1,\n",
       " 'german': 122,\n",
       " 'wankle': 1,\n",
       " 'rotary': 1,\n",
       " 'miller': 8,\n",
       " 'cycle': 6,\n",
       " 'engines': 129,\n",
       " 'introduced': 21,\n",
       " 'vtec': 10,\n",
       " 'etc': 269,\n",
       " 'leans': 2,\n",
       " 'strongly': 24,\n",
       " 'ceo': 4,\n",
       " 'bonuses': 1,\n",
       " 'refinement': 14,\n",
       " 'polish': 5,\n",
       " 'falling': 12,\n",
       " 'wayside': 1,\n",
       " 'casuality': 1,\n",
       " 'heavy': 56,\n",
       " 'handed': 5,\n",
       " 'style': 104,\n",
       " 'truly': 41,\n",
       " 'critical': 9,\n",
       " 'things': 255,\n",
       " 'mention': 96,\n",
       " 'bumper-to-bumper': 1,\n",
       " 'demands': 2,\n",
       " 'driver': 269,\n",
       " 'books': 5,\n",
       " 'let': 237,\n",
       " 'apply': 17,\n",
       " 'gas': 279,\n",
       " 'push': 51,\n",
       " 'glide': 3,\n",
       " 'repeat': 15,\n",
       " 'snooze': 1,\n",
       " 'edmunds': 90,\n",
       " 'new': 950,\n",
       " 'feature': 49,\n",
       " 'called': 80,\n",
       " 'true': 194,\n",
       " 'cost': 200,\n",
       " 'listed': 29,\n",
       " 'researches': 1,\n",
       " 'vehicles': 220,\n",
       " 'heading': 10,\n",
       " '13': 16,\n",
       " 'subjects': 8,\n",
       " 'hyundai': 176,\n",
       " 'particular': 45,\n",
       " 'vehicle': 293,\n",
       " 'useful': 27,\n",
       " 'comparing': 119,\n",
       " 'takes': 75,\n",
       " 'purchase': 75,\n",
       " 'price': 535,\n",
       " 'adds': 18,\n",
       " 'depreciation': 17,\n",
       " 'insurance': 52,\n",
       " 'license': 9,\n",
       " 'fees': 9,\n",
       " 'gives': 52,\n",
       " 'figure': 72,\n",
       " '5-yr': 1,\n",
       " 'ownership': 39,\n",
       " 'tailor': 1,\n",
       " 'zip': 4,\n",
       " 'code': 5,\n",
       " 'tried': 48,\n",
       " 'chance': 47,\n",
       " 'person': 107,\n",
       " '38k': 11,\n",
       " 'volkwagen': 109,\n",
       " 'w8': 12,\n",
       " 'entry': 178,\n",
       " '-level': 1,\n",
       " 'luxury': 693,\n",
       " 'sedan': 967,\n",
       " 'category': 134,\n",
       " 'upcoming': 37,\n",
       " 'year': 367,\n",
       " 'drive': 997,\n",
       " 'bimmer': 112,\n",
       " 'night': 31,\n",
       " 'day': 210,\n",
       " 'volkswagen': 215,\n",
       " 'nice': 318,\n",
       " 'inside': 87,\n",
       " 'good': 817,\n",
       " 'cruising': 31,\n",
       " 'handling': 510,\n",
       " 'akin': 7,\n",
       " 'riding': 13,\n",
       " 'pig': 10,\n",
       " 'hurry': 4,\n",
       " 'beg': 7,\n",
       " 'differ.while': 1,\n",
       " 'admit': 70,\n",
       " 'biased': 46,\n",
       " 'obviously': 82,\n",
       " 'bought': 210,\n",
       " 'believe': 318,\n",
       " 'sedan.i': 3,\n",
       " 'test': 517,\n",
       " 'drove': 267,\n",
       " 'bmw': 4479,\n",
       " 'making': 122,\n",
       " 'final': 44,\n",
       " 'choice': 172,\n",
       " 'suppose': 31,\n",
       " 'term': 46,\n",
       " '145': 9,\n",
       " '146': 132,\n",
       " 'defined': 17,\n",
       " 'number': 137,\n",
       " 'ways': 44,\n",
       " 'offers': 82,\n",
       " '150': 40,\n",
       " 'don': 33,\n",
       " 't.': 5,\n",
       " 'isn': 3,\n",
       " 't': 95,\n",
       " 'recent': 72,\n",
       " 'nissan': 483,\n",
       " 'tag': 13,\n",
       " 'straight': 73,\n",
       " 'acceleration': 155,\n",
       " 'instance': 28,\n",
       " 'literature': 3,\n",
       " 'quotes': 20,\n",
       " '0': 42,\n",
       " '60': 126,\n",
       " '6.5': 16,\n",
       " 'sec': 44,\n",
       " 'pretty': 269,\n",
       " 'quick': 55,\n",
       " '4': 209,\n",
       " 'door': 61,\n",
       " 'fearless': 1,\n",
       " 'prediction': 1,\n",
       " 'future': 70,\n",
       " 'numbers': 256,\n",
       " 'sec.': 2,\n",
       " 'claims': 13,\n",
       " 'quarter': 24,\n",
       " 'mile': 92,\n",
       " '15.0': 2,\n",
       " '94': 5,\n",
       " '95.': 1,\n",
       " 'base': 90,\n",
       " '2000': 46,\n",
       " 'comparison': 192,\n",
       " 'included': 67,\n",
       " 'lincoln': 60,\n",
       " 'ls8': 6,\n",
       " 'sport': 428,\n",
       " 'audi': 988,\n",
       " '2.7tt': 1,\n",
       " 'tested': 87,\n",
       " 'identical': 22,\n",
       " 'curb': 7,\n",
       " 'weight': 186,\n",
       " 'wheel': 179,\n",
       " 'tire': 100,\n",
       " 'size': 176,\n",
       " 'tiptronic': 9,\n",
       " 'hp': 491,\n",
       " 'tq': 6,\n",
       " '250': 38,\n",
       " '258.': 1,\n",
       " 'results': 90,\n",
       " '6.6': 5,\n",
       " '15.1': 3,\n",
       " '94.': 1,\n",
       " '270': 32,\n",
       " '273': 1,\n",
       " 'ought': 14,\n",
       " 'slightly': 60,\n",
       " 'better': 996,\n",
       " 'll': 9,\n",
       " 'btw': 87,\n",
       " 'turned': 48,\n",
       " '7.5': 7,\n",
       " '15.7': 3,\n",
       " '90.': 2,\n",
       " 'previous': 82,\n",
       " 'reasonable': 32,\n",
       " 'feels': 94,\n",
       " 'quicker': 27,\n",
       " 'setting': 15,\n",
       " 'aside': 34,\n",
       " 'notorious': 3,\n",
       " 'un-reliability': 1,\n",
       " 's': 127,\n",
       " 'butt': 20,\n",
       " 'dyno': 11,\n",
       " 'pull': 43,\n",
       " 'lateral': 12,\n",
       " 'g': 482,\n",
       " '3': 870,\n",
       " 'series': 578,\n",
       " 'w/sport': 14,\n",
       " 'package': 295,\n",
       " 'certainly': 121,\n",
       " 'aggressive': 23,\n",
       " 'rubber': 22,\n",
       " 'expect': 96,\n",
       " 'provide': 31,\n",
       " 'grip': 23,\n",
       " 'entertainment': 6,\n",
       " 'value': 291,\n",
       " 'sane': 4,\n",
       " 'public': 35,\n",
       " 'road': 363,\n",
       " 'speed': 282,\n",
       " 'opinions.cheers': 1,\n",
       " 'rayoff': 1,\n",
       " 'shortly': 5,\n",
       " 'break-in': 9,\n",
       " 'miles': 249,\n",
       " 'lunch': 17,\n",
       " 'recently': 48,\n",
       " 'went': 109,\n",
       " 'list': 154,\n",
       " 'heaven': 6,\n",
       " 'best': 648,\n",
       " 'shifter/clutch': 1,\n",
       " 'power': 504,\n",
       " 'great': 543,\n",
       " 'motor': 77,\n",
       " 'fas': 1,\n",
       " 'smoothness': 13,\n",
       " 'interior': 509,\n",
       " 'average': 118,\n",
       " 'leather': 126,\n",
       " 'wood': 40,\n",
       " 'helps': 30,\n",
       " 'dig': 23,\n",
       " \"don't.330i\": 1,\n",
       " 'find': 271,\n",
       " 'linear': 13,\n",
       " 'sensation': 5,\n",
       " 'thrust': 11,\n",
       " 'lacking': 31,\n",
       " 'sunroof': 32,\n",
       " 'std': 10,\n",
       " 'plus': 120,\n",
       " '17': 39,\n",
       " 'wheels': 187,\n",
       " 'all-seasons': 18,\n",
       " 'pricy.is300-': 1,\n",
       " 'manual': 467,\n",
       " 'tranny': 128,\n",
       " 'smooth': 89,\n",
       " 'hate': 52,\n",
       " 'claustrophobic': 3,\n",
       " 'chintzy': 1,\n",
       " 'x-type': 230,\n",
       " 'liked': 82,\n",
       " '3.0l': 30,\n",
       " 'grey': 7,\n",
       " 'stained': 1,\n",
       " 'maple': 4,\n",
       " 'jaguar': 167,\n",
       " 'nearly': 86,\n",
       " 'purchased': 38,\n",
       " 'british': 12,\n",
       " 'racing': 77,\n",
       " 'green': 21,\n",
       " 'ivory': 4,\n",
       " 'beautiful': 57,\n",
       " 'walnut': 1,\n",
       " 'options': 124,\n",
       " 'riciulously': 1,\n",
       " 'overpriced': 42,\n",
       " 'bargain': 13,\n",
       " 'hunter': 1,\n",
       " 'bad': 271,\n",
       " 'ride': 237,\n",
       " 'brakes': 99,\n",
       " 'strong': 41,\n",
       " 'thing': 369,\n",
       " '0-60': 221,\n",
       " 'advertised': 3,\n",
       " 'nicest': 5,\n",
       " 'overall.a4': 1,\n",
       " '3.0': 102,\n",
       " 'porky': 6,\n",
       " 'ponderous': 3,\n",
       " 'easily': 70,\n",
       " 'worst': 54,\n",
       " 'available': 136,\n",
       " 'segment': 119,\n",
       " 'barely': 24,\n",
       " 'tell': 170,\n",
       " 'leatherette': 8,\n",
       " 'cheap': 97,\n",
       " 'opt': 21,\n",
       " 'way': 596,\n",
       " 'better.s4': 1,\n",
       " '2001': 44,\n",
       " 'fast': 204,\n",
       " 'thought': 209,\n",
       " '99': 42,\n",
       " 'ford': 289,\n",
       " 'rockets': 3,\n",
       " 'impressive': 45,\n",
       " 'nicer': 25,\n",
       " 'seat': 407,\n",
       " 'support': 40,\n",
       " 'gloomy': 1,\n",
       " '250bhp': 2,\n",
       " '258': 6,\n",
       " 'lb': 12,\n",
       " 'ft.': 11,\n",
       " 'audible': 6,\n",
       " 'delight': 6,\n",
       " '2002': 75,\n",
       " 'sounds': 76,\n",
       " 'amazing': 43,\n",
       " 'compared': 180,\n",
       " 'think': 1240,\n",
       " 'backpressure': 1,\n",
       " 'gobbled': 1,\n",
       " 'exhaust': 43,\n",
       " 'note': 50,\n",
       " 'perfect': 71,\n",
       " 'giving': 31,\n",
       " 'away': 145,\n",
       " '9000': 2,\n",
       " 'msrp': 138,\n",
       " 'people': 877,\n",
       " 'definitely': 113,\n",
       " 'buying': 199,\n",
       " 'looked': 101,\n",
       " 'dated': 8,\n",
       " 'ones.g35': 1,\n",
       " 'showroom': 8,\n",
       " 'impressed': 51,\n",
       " 'interested': 55,\n",
       " 'bit': 230,\n",
       " 'torque': 355,\n",
       " 'lacked': 13,\n",
       " 'neat': 11,\n",
       " 'touches': 5,\n",
       " 'rear': 199,\n",
       " 'passengers': 21,\n",
       " 'dynamics': 42,\n",
       " 'left': 105,\n",
       " 'cold': 26,\n",
       " 'maybe': 337,\n",
       " 'early': 57,\n",
       " 'model': 201,\n",
       " 'dicker': 1,\n",
       " 'sticker': 40,\n",
       " 'close.lincoln': 1,\n",
       " 'ls': 46,\n",
       " 'v6': 180,\n",
       " 'crisp': 7,\n",
       " '5': 310,\n",
       " 'engine': 627,\n",
       " 'thrashy': 1,\n",
       " 'revs': 13,\n",
       " 'particularly': 21,\n",
       " 'needs': 122,\n",
       " 'revved': 4,\n",
       " 'susp.acura': 1,\n",
       " 'tl-s': 20,\n",
       " 'auto': 277,\n",
       " 'incredible': 20,\n",
       " 'favourite': 4,\n",
       " 'sound': 101,\n",
       " 'concerned': 58,\n",
       " 'so-so': 3,\n",
       " 'excellent': 98,\n",
       " 'price.volvo': 1,\n",
       " 'volvo': 234,\n",
       " 't5': 23,\n",
       " 'chose': 32,\n",
       " 'come': 248,\n",
       " '3bhp': 1,\n",
       " '15': 65,\n",
       " 'lb.ft': 4,\n",
       " 'close': 184,\n",
       " 'lighter': 30,\n",
       " 'fwd': 547,\n",
       " 'steer': 150,\n",
       " 'evident': 9,\n",
       " '8/10ths': 5,\n",
       " 'question': 122,\n",
       " 'stereo': 45,\n",
       " 'steering': 209,\n",
       " 'falls': 24,\n",
       " 'grabby': 3,\n",
       " 'decent': 64,\n",
       " '100km/h': 1,\n",
       " 'pulls': 27,\n",
       " 'hardest': 2,\n",
       " 'consideration': 26,\n",
       " 'cheaper': 59,\n",
       " 'cts': 336,\n",
       " 'sure': 384,\n",
       " 'conclusion': 26,\n",
       " 'nitpick': 2,\n",
       " 'fine': 134,\n",
       " 'driveway': 15,\n",
       " 'honestly': 38,\n",
       " 'grave': 2,\n",
       " 'misfortune': 3,\n",
       " 'league': 19,\n",
       " 'lesser': 17,\n",
       " 'acura/lexus/jag': 1,\n",
       " 'gasp': 3,\n",
       " 'rough': 27,\n",
       " 'felt': 143,\n",
       " 'lots': 87,\n",
       " 'hard': 233,\n",
       " 'plastic': 21,\n",
       " 'substantial': 13,\n",
       " 'soft-touch': 3,\n",
       " 'materials': 44,\n",
       " 'throttle': 56,\n",
       " 'response': 31,\n",
       " 'weak': 29,\n",
       " 'required': 17,\n",
       " 'excessive': 7,\n",
       " 'modulation': 1,\n",
       " 'awkward': 2,\n",
       " 'pedal': 49,\n",
       " 'rolling': 17,\n",
       " 'bed': 4,\n",
       " '1998': 10,\n",
       " 'technology': 43,\n",
       " 'brake': 63,\n",
       " 'distribution': 34,\n",
       " 'salesmen': 3,\n",
       " 'kept': 20,\n",
       " 'insisting': 2,\n",
       " 'channel': 12,\n",
       " 'abs': 17,\n",
       " 'mags': 49,\n",
       " 'slow': 67,\n",
       " 'reacting': 5,\n",
       " 'boat': 35,\n",
       " 'turn': 122,\n",
       " 'undulate': 2,\n",
       " 'slowly': 10,\n",
       " 'directions': 2,\n",
       " 'fact': 282,\n",
       " 'salesguy': 4,\n",
       " 'asked': 50,\n",
       " 'told': 46,\n",
       " 'real': 247,\n",
       " 'competitor': 24,\n",
       " 'germans': 30,\n",
       " 'snorted': 2,\n",
       " 'reminded': 8,\n",
       " 'cadillac': 179,\n",
       " 'sports': 240,\n",
       " 'yeah': 126,\n",
       " 'sit': 38,\n",
       " 'lot': 366,\n",
       " 'heaps': 1,\n",
       " 'congradulations': 1,\n",
       " 'looking': 339,\n",
       " 'hope': 110,\n",
       " 'happy': 104,\n",
       " 'saw': 82,\n",
       " 'morning': 22,\n",
       " 'fun': 312,\n",
       " 'hey': 59,\n",
       " 'blueguy': 68,\n",
       " 'wrond': 1,\n",
       " 'know': 769,\n",
       " 'type': 110,\n",
       " 'gearbox': 10,\n",
       " '300': 109,\n",
       " 'twisting': 1,\n",
       " 'need': 387,\n",
       " 'honesty': 2,\n",
       " 'incredibly': 13,\n",
       " 'easy': 73,\n",
       " 'modulate': 2,\n",
       " 'hevay': 1,\n",
       " 'purpose': 19,\n",
       " 'missed': 24,\n",
       " 'gear': 126,\n",
       " 'said': 418,\n",
       " '6-speed': 90,\n",
       " 'jagboyxkr': 1,\n",
       " 'right': 441,\n",
       " 'end': 219,\n",
       " '10000cdn': 1,\n",
       " 'ridiculous': 27,\n",
       " 'needed': 46,\n",
       " 'split': 20,\n",
       " 'fold': 10,\n",
       " 'bundled': 2,\n",
       " 'xenons': 16,\n",
       " 'twice': 33,\n",
       " 'asmuch': 1,\n",
       " '1600.00': 1,\n",
       " '1600.00.': 1,\n",
       " 'unbeleivable': 1,\n",
       " 'lease': 111,\n",
       " 'rate': 45,\n",
       " 'low': 141,\n",
       " '1.9': 5,\n",
       " 'helped': 10,\n",
       " 'difference.i': 4,\n",
       " 'care': 171,\n",
       " 'anybody': 27,\n",
       " 'says': 102,\n",
       " 'driven': 296,\n",
       " 'imo': 110,\n",
       " 'canada': 12,\n",
       " 'awd': 519,\n",
       " 'recommended': 14,\n",
       " 'gets': 171,\n",
       " 'slaughtered': 1,\n",
       " 'priced': 46,\n",
       " 'equal': 66,\n",
       " 'leader': 23,\n",
       " 'class': 358,\n",
       " 'suicide': 1,\n",
       " 'hot': 45,\n",
       " 'market.the': 2,\n",
       " 'broken': 31,\n",
       " 'nicely': 35,\n",
       " 'expected': 33,\n",
       " 'sheer': 11,\n",
       " '100km': 1,\n",
       " 'h': 14,\n",
       " 'beat': 108,\n",
       " 'start': 111,\n",
       " '18': 43,\n",
       " 'wheeler': 1,\n",
       " 'imagine': 58,\n",
       " 'big': 285,\n",
       " 'rig': 2,\n",
       " 'thanks': 157,\n",
       " 'informative': 4,\n",
       " 'congratulations': 3,\n",
       " 'eat': 38,\n",
       " 'sandwich': 2,\n",
       " 'roll': 27,\n",
       " 'up/down': 3,\n",
       " 'windows': 35,\n",
       " 'test-drove': 5,\n",
       " \"'98a4quattro\": 1,\n",
       " '2.8': 8,\n",
       " '325ci,325xi': 1,\n",
       " 'loved': 44,\n",
       " 'bimmers': 38,\n",
       " 'steptronic': 16,\n",
       " 'absolute': 18,\n",
       " 'joy': 11,\n",
       " '1993dodge': 1,\n",
       " 'p.o.s': 1,\n",
       " '150miles': 1,\n",
       " 'complaints': 8,\n",
       " 'extremely': 31,\n",
       " 'satisified': 1,\n",
       " 'decision': 89,\n",
       " 'eating': 8,\n",
       " 'drinking': 3,\n",
       " 'windowing': 1,\n",
       " 'lol': 82,\n",
       " 'sunroofing': 1,\n",
       " 'actually': 304,\n",
       " 'owned': 118,\n",
       " 'carrying': 5,\n",
       " 'tasks': 2,\n",
       " 'walking': 4,\n",
       " 'got': 454,\n",
       " 'guess': 266,\n",
       " 'guys': 106,\n",
       " 'experienced': 21,\n",
       " 'manuals': 46,\n",
       " 'someday': 6,\n",
       " 'rich': 20,\n",
       " 'famous': 7,\n",
       " 'porsche': 96,\n",
       " 'sequential': 11,\n",
       " 'shifter': 44,\n",
       " 'stones': 4,\n",
       " 'casted': 2,\n",
       " 'remind': 7,\n",
       " 'forums.cmnott': 1,\n",
       " 'respect': 45,\n",
       " 'disagree': 57,\n",
       " 'owner': 72,\n",
       " 'personally': 87,\n",
       " '3000': 6,\n",
       " 'second': 168,\n",
       " '3.0.': 14,\n",
       " 'dissapointed': 3,\n",
       " 'th': 8,\n",
       " '250-260': 1,\n",
       " 'solve': 1,\n",
       " 'highway': 134,\n",
       " 'speeds': 53,\n",
       " 'honetsly': 1,\n",
       " 'mondeo': 8,\n",
       " 'excuse': 25,\n",
       " 'going': 486,\n",
       " 'fall': 49,\n",
       " 'apart': 16,\n",
       " 'negative': 34,\n",
       " 'headlines': 2,\n",
       " 'oh': 115,\n",
       " 'came': 132,\n",
       " 'different': 387,\n",
       " 'considering': 87,\n",
       " 'won': 48,\n",
       " 'me.acceleration': 1,\n",
       " 'times': 184,\n",
       " 'clearly': 37,\n",
       " 'states': 20,\n",
       " 'subjectively': 4,\n",
       " 'instrumented': 1,\n",
       " 'runs': 23,\n",
       " 'revealed': 6,\n",
       " 'measured': 18,\n",
       " '0-to-60-mph': 1,\n",
       " '6.3': 12,\n",
       " 'seconds': 99,\n",
       " '0.2': 3,\n",
       " 'slower': 37,\n",
       " 'small': 156,\n",
       " 'v-6': 27,\n",
       " 'similarly': 20,\n",
       " 'bavarian': 1,\n",
       " 'in-line': 6,\n",
       " 'track': 200,\n",
       " 'quickest': 4,\n",
       " 'accompanied': 2,\n",
       " 'nice-but-distant': 1,\n",
       " 'goes': 93,\n",
       " 'mph': 274,\n",
       " 'undercutting': 2,\n",
       " 'boy-racer': 3,\n",
       " 'lexus': 483,\n",
       " '7.1': 6,\n",
       " 'mercedes': 699,\n",
       " 'c320': 31,\n",
       " '6.8': 7,\n",
       " 'matching': 9,\n",
       " '-jaguar': 1,\n",
       " '.-audi': 1,\n",
       " 'transmission.handling': 1,\n",
       " 'handle': 95,\n",
       " 'r': 61,\n",
       " 'chassis': 56,\n",
       " 'redolent': 2,\n",
       " 'complained': 8,\n",
       " 'work': 172,\n",
       " 'modern': 26,\n",
       " 'well-balanced': 2,\n",
       " 'balance': 66,\n",
       " 'corners': 61,\n",
       " 'long': 284,\n",
       " 'stretch': 13,\n",
       " 'curving': 2,\n",
       " 'mountain': 17,\n",
       " 'inevitably': 5,\n",
       " 'walkietalkies': 1,\n",
       " 'carry': 21,\n",
       " \"'this\": 3,\n",
       " 'curves': 19,\n",
       " 'confidence-inspiring': 2,\n",
       " 'precise': 24,\n",
       " 'turn-in': 9,\n",
       " 'optional': 26,\n",
       " '3.0-liter': 2,\n",
       " '4-cam': 2,\n",
       " 'expensive': 140,\n",
       " '2.5': 51,\n",
       " 'version': 110,\n",
       " 'respectable': 8,\n",
       " '231': 2,\n",
       " 'bhp': 4,\n",
       " 'keeping': 33,\n",
       " 'company': 99,\n",
       " 'effort': 16,\n",
       " 'suspension': 166,\n",
       " 'engineers': 33,\n",
       " 'wanted': 139,\n",
       " \"'connected\": 1,\n",
       " 'relaxed': 5,\n",
       " \"'and\": 1,\n",
       " 'wrap': 2,\n",
       " 'given': 123,\n",
       " 'soft': 91,\n",
       " 'delivers': 6,\n",
       " 'surprisingly': 5,\n",
       " 'dynamically': 4,\n",
       " 'all-wheel-drive': 14,\n",
       " 'looks': 272,\n",
       " 'handles': 72,\n",
       " 'superb': 9,\n",
       " 'accomplishes': 1,\n",
       " 'goals': 7,\n",
       " 'rubbery': 4,\n",
       " 'tuning': 12,\n",
       " 'short': 73,\n",
       " 'missing': 39,\n",
       " 'firm': 21,\n",
       " 'rally-car': 1,\n",
       " 'edge': 31,\n",
       " 'sense': 82,\n",
       " 'precision': 14,\n",
       " 'delightful': 2,\n",
       " 'sporty': 89,\n",
       " 'despite': 37,\n",
       " '750': 6,\n",
       " 'noticed': 41,\n",
       " 'whoop-de-dos': 1,\n",
       " 'desert': 3,\n",
       " \"'considerable\": 1,\n",
       " 'excitement': 14,\n",
       " 'simply': 148,\n",
       " 'floaty': 5,\n",
       " 'loose': 15,\n",
       " 'pay': 172,\n",
       " 'noted': 23,\n",
       " '220-bhp': 1,\n",
       " 'dohc': 8,\n",
       " 'aluminum': 25,\n",
       " 'reasonably': 22,\n",
       " 'peppy': 3,\n",
       " 'pack': 31,\n",
       " 'trend': 37,\n",
       " 'zf': 2,\n",
       " 'servotronic': 1,\n",
       " 'ii': 5,\n",
       " 'variable-ratio': 1,\n",
       " 'speed-sensitive': 3,\n",
       " 'rack-and-pinion': 2,\n",
       " 'system': 226,\n",
       " 'matches': 5,\n",
       " 'previously': 12,\n",
       " 'unrivaled': 1,\n",
       " 'served': 6,\n",
       " 'placement': 5,\n",
       " 'laser-guided': 1,\n",
       " 'feedback': 29,\n",
       " 'complete': 26,\n",
       " 'confidence': 9,\n",
       " 'fingertips': 1,\n",
       " '120': 14,\n",
       " 'offering': 30,\n",
       " 'similar': 111,\n",
       " 'levels': 11,\n",
       " 'communication': 3,\n",
       " 'skyline': 8,\n",
       " 'gt-r': 10,\n",
       " 'racy': 4,\n",
       " 'piece': 18,\n",
       " 'criticized': 5,\n",
       " 'feeling': 51,\n",
       " 'c': 223,\n",
       " 'd': 141,\n",
       " 'vibrates': 3,\n",
       " 'peak': 15,\n",
       " 'terrific': 14,\n",
       " 'enthusiast': 47,\n",
       " 'goods': 3,\n",
       " '.forbes': 1,\n",
       " 'x': 57,\n",
       " 'boast': 3,\n",
       " 'agree': 298,\n",
       " 'known': 47,\n",
       " 'develped': 1,\n",
       " '22': 20,\n",
       " 'years': 466,\n",
       " 'iv': 2,\n",
       " 'newest': 6,\n",
       " 'divides': 2,\n",
       " '50/50': 16,\n",
       " 'slip': 16,\n",
       " 'detected': 3,\n",
       " 'systems': 38,\n",
       " 'minor': 34,\n",
       " 'turbocharged': 10,\n",
       " '1.8-liter': 1,\n",
       " '4-cylinder': 5,\n",
       " 'versions': 34,\n",
       " 'larger': 61,\n",
       " 'prove': 37,\n",
       " 'certain': 77,\n",
       " 'conditions': 59,\n",
       " 'setups': 7,\n",
       " 'later': 60,\n",
       " 'banned': 5,\n",
       " 'races': 27,\n",
       " 'advantages.jaguar': 1,\n",
       " 'uses': 39,\n",
       " 'designed': 54,\n",
       " 'traction': 128,\n",
       " '40': 52,\n",
       " 'specially': 6,\n",
       " 'roller': 3,\n",
       " 'bearings': 2,\n",
       " 'fitted': 4,\n",
       " 'tops': 12,\n",
       " 'strut': 2,\n",
       " 'towers': 1,\n",
       " 'body': 102,\n",
       " 'advanced': 12,\n",
       " 'mechanism': 2,\n",
       " 'rwd': 679,\n",
       " 'unlike': 23,\n",
       " 'produces': 14,\n",
       " 'interphere': 1,\n",
       " 'purity': 2,\n",
       " 'steering.forbes': 1,\n",
       " 'stated': 54,\n",
       " 'seemless': 2,\n",
       " 'transparent': 2,\n",
       " '40/60': 3,\n",
       " 'viscous': 1,\n",
       " 'coupling': 1,\n",
       " 'dynamic': 9,\n",
       " 'stability': 18,\n",
       " 'control': 105,\n",
       " 'rivals': 6,\n",
       " 'vaunted': 4,\n",
       " 'wet-': 1,\n",
       " 'dry-': 1,\n",
       " 'weather': 48,\n",
       " 'balanced': 38,\n",
       " 'understeer': 29,\n",
       " 'set': 147,\n",
       " 'safe': 69,\n",
       " 'secure': 12,\n",
       " 'signals': 7,\n",
       " 'happen': 51,\n",
       " 'plenty': 55,\n",
       " 'adjust': 10,\n",
       " 'braking': 85,\n",
       " 'features': 165,\n",
       " 'vented': 6,\n",
       " 'solid': 61,\n",
       " 'discs': 5,\n",
       " 's-type.road': 1,\n",
       " 'tests': 86,\n",
       " 'repeatable': 2,\n",
       " 'stopping': 9,\n",
       " 'distances': 3,\n",
       " '118': 5,\n",
       " '80': 48,\n",
       " '208': 3,\n",
       " 'articles': 22,\n",
       " 'exceptional': 3,\n",
       " 'comparable': 76,\n",
       " 'laps': 4,\n",
       " 'castle': 1,\n",
       " 'combe': 1,\n",
       " 'racetrack': 20,\n",
       " 'allowed': 14,\n",
       " 'explore': 2,\n",
       " 'outer': 3,\n",
       " 'reaches': 2,\n",
       " 'proved': 8,\n",
       " 'completely': 58,\n",
       " 'benign': 3,\n",
       " 'limit': 52,\n",
       " 'grinds': 1,\n",
       " 'tires': 439,\n",
       " 'excessively': 1,\n",
       " 'tail': 21,\n",
       " 'flick': 3,\n",
       " 'simultaneously': 1,\n",
       " 'lifting': 3,\n",
       " 'four-wheel': 3,\n",
       " 'disc': 12,\n",
       " ...}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist = dict(nltk.FreqDist(word for word in txt_combined))\n",
    "freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca1dc71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_dist = {}\n",
    "brand_list = model_brand_mapping[\"brand\"]\n",
    "\n",
    "for brand in brand_list:\n",
    "    brand_dist[brand] = freq_dist.get(brand, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9bed569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acura': 2697,\n",
       " 'audi': 988,\n",
       " 'bmw': 4479,\n",
       " 'buick': 29,\n",
       " 'cadillac': 179,\n",
       " 'car': 5916,\n",
       " 'chevrolet': 184,\n",
       " 'chrysler': 121,\n",
       " 'dodge': 67,\n",
       " 'ford': 289,\n",
       " 'honda': 654,\n",
       " 'hyndai kia': None,\n",
       " 'hyundai': 176,\n",
       " 'hyundai,': None,\n",
       " 'hyundai.': None,\n",
       " 'infiniti': 1922,\n",
       " 'kia': 25,\n",
       " 'kia,': None,\n",
       " 'kia.': None,\n",
       " 'lincoln': 60,\n",
       " 'mazda': 99,\n",
       " 'mercedes': 699,\n",
       " 'mercury': 9,\n",
       " 'mitsubishi': 27,\n",
       " 'nissan': 483,\n",
       " 'nissan.': None,\n",
       " 'pontiac': 68,\n",
       " 'problem': 372,\n",
       " 'saturn': 12,\n",
       " 'seat': 407,\n",
       " 'sedan': 967,\n",
       " 'subaru': 370,\n",
       " 'suzuki': 21,\n",
       " 'toyata': None,\n",
       " 'toyota': 405,\n",
       " 'volkswagen': 215,\n",
       " 'volkwagen': 109,\n",
       " 'volvo': 234}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b94eec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_brands = []\n",
    "freq_count = []\n",
    "\n",
    "for key, value in brand_dist.items():\n",
    "    if value is not None:\n",
    "        if key not in (\"car\", \"problem\", \"seat\"):\n",
    "            cleaned_brands.append(key)\n",
    "            freq_count.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e48c0757",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_dist_df = pd.DataFrame({\"brand\": cleaned_brands,\n",
    "                              \"freq_count\": freq_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d7759772",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_freq_dist = brands_dist_df.sort_values(\"freq_count\", ascending = False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd3614c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>freq_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bmw</td>\n",
       "      <td>4479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acura</td>\n",
       "      <td>2697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>infiniti</td>\n",
       "      <td>1922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audi</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sedan</td>\n",
       "      <td>967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mercedes</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>honda</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nissan</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>toyota</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>subaru</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      brand  freq_count\n",
       "0       bmw        4479\n",
       "1     acura        2697\n",
       "2  infiniti        1922\n",
       "3      audi         988\n",
       "4     sedan         967\n",
       "5  mercedes         699\n",
       "6     honda         654\n",
       "7    nissan         483\n",
       "8    toyota         405\n",
       "9    subaru         370"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show top 10\n",
    "sorted_freq_dist.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c5945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813acffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8580fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the document-term matrix to a dense array\n",
    "dtm_array = dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1625b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate lift between terms\n",
    "term_lift = np.dot(dtm_array.T, dtm_array)\n",
    "term_occurrence = np.sum(dtm_array, axis=0)\n",
    "# + 1e-8 is added to avoid division by zero\n",
    "lift_matrix = term_lift / (np.outer(term_occurrence, term_occurrence) + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07d4481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dissimilarity matrix based on lift\n",
    "dissimilarity_matrix = 1 / lift_matrix\n",
    "print(dissimilarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814653cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply MDS to reduce dimensionality to 2D\n",
    "mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42) \n",
    "# create two components for each of the feature/word we have\n",
    "mds_result = mds.fit_transform(dissimilarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1aded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the MDS result\n",
    "plt.scatter(mds_result[:, 0], mds_result[:, 1])\n",
    "\n",
    "# Annotate points with feature names\n",
    "for i, txt in enumerate(feature_names):\n",
    "    plt.annotate(txt, (mds_result[i, 0], mds_result[i, 1]))\n",
    "\n",
    "plt.title('MDS Plot based on Lift for Non-stopwords')\n",
    "plt.xlabel('MDS Dimension 1')\n",
    "plt.ylabel('MDS Dimension 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9476f465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
